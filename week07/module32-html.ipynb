{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing HTML with BeautifulSoup\n",
    "\n",
    "In this example, we want to look at a website and get a list of all the available downloadable files from that website.\n",
    "\n",
    "https://catalog.data.gov/dataset?res_format=CSV&tags=hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://catalog.data.gov/dataset?res_format=CSV&tags=hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('h3'):\n",
    "    print(link.a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in soup.find_all('li', 'dataset-item'):\n",
    "    name = element.h3.text.strip()\n",
    "    resources = element.ul\n",
    "    for item in resources.find_all('li'):\n",
    "        if item.text.strip() == 'CSV':\n",
    "            print(\"Download information about '{}' from {}\".format(name,item.a.attrs['href']))\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Table Data\n",
    "\n",
    "\n",
    "In this example, we're going to find an HTML table and extract the data from that table\n",
    "\n",
    "https://open.epic.com/Clinical/Allergy - Error Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://open.epic.com/Clinical/Allergy'\n",
    "r  = requests.get(url)\n",
    "data = r.text\n",
    "\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "table = soup.find('table',id='errors')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In HTML tables, there is usually a <thead> section to tell us what the column headers are.\n",
    "# Let's load those into a simple list of headers[]\n",
    "headers = []\n",
    "for cell in table.thead.tr.find_all('th'):\n",
    "    headers.append(cell.text)\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In HTML tables, the rows are in a <tbody> section\n",
    "errors = {}\n",
    "for row in table.tbody.find_all('tr'):\n",
    "    colnum = 0\n",
    "    for cell in row.find_all('td'):\n",
    "        if colnum == 0:\n",
    "            error_cd = cell.text\n",
    "            errors.setdefault(error_cd, {})\n",
    "        else:\n",
    "            column = headers[colnum]\n",
    "            errors[error_cd][column] = cell.text\n",
    "        colnum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(errors, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.get('4119')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.get('4119')['Severity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading HTML Tables with Pandas\n",
    "\n",
    "Pandas has the ability to read HTML, too.  In ideal circumstances, it will scour whatever page you give it and find all of the tables there.  The result from `read_html()` will be a list of dataframes.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_html('https://open.epic.com/Clinical/Allergy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
